---
title: "MATH 216 Homework 4"
author: "Joy Wood"
output: html_document
---

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# For data manipulation and visualization
suppressPackageStartupMessages(library(mosaic))
suppressPackageStartupMessages(library(spdep))
suppressPackageStartupMessages(library(stringr))
suppressPackageStartupMessages(library(dplyr))
suppressPackageStartupMessages(library(ggplot2))
suppressPackageStartupMessages(library(tidyr))
suppressPackageStartupMessages(library(knitr))
# For US county and state maps
suppressPackageStartupMessages(library(sp))
suppressPackageStartupMessages(library(rgeos))
suppressPackageStartupMessages(library(maps))
# For loading in shapefiles
suppressPackageStartupMessages(library(rgdal))
suppressPackageStartupMessages(library(maptools))
# For interactive maps
suppressPackageStartupMessages(library(leaflet))
```

## Admistrative:

Please indicate

* Who you collaborated with: talked to Christian about data and leaflet
* Roughly how much time you spent on this HW: ~9 hours
* What gave you the most trouble: 1.B Spatial Autocorrelation
* Any comments you have: Uggggh. Really struggled.


## Question 1:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
# Load state and county map of US in 2010 from the maps package and convert them
# to data frames so that we can ggplot them.
US_state <- map_data("state") %>% 
  tbl_df()
US_county <- map_data("county") %>% 
  tbl_df()
county_data <- read.csv("data/COUNTY.csv", header=TRUE) %>% 
  tbl_df()
```

### Choropleth Map of US Voter Behavior in 2000
```{r, echo=FALSE, message=FALSE, warning=FALSE}
clean_text <- function(text){
  text <- gsub("[^[:alnum:]]", "", text)
  text <- gsub(" ", "", text)
  text <- tolower(str_trim(text))
  return(text)
}
#factor to num
county_data$PNADER <- as.numeric(as.character(county_data$PNADER ))
county_data$PGORE <- as.numeric(as.character(county_data$PGORE ))
county_data$PBUSH <- as.numeric(as.character(county_data$PBUSH))

#replace na with 0
county_data$PNADER[is.na(county_data$PNADER)] <- 0
county_data$PBUSH[is.na(county_data$PBUSH)] <- 0
county_data$PGORE[is.na(county_data$PGORE)] <- 0

#clean text
US_county$region <- clean_text(US_county$region)
US_county$subregion <- clean_text(US_county$subregion)
county_data$STATE <- clean_text(county_data$STATE)
county_data$COUNTY <- clean_text(county_data$COUNTY)
county_data$STATE <- clean_text(county_data$STATE)
county_data$COUNTY <- clean_text(county_data$COUNTY)

#aggregate democrats
county_data$PNADER_PGORE <- county_data$PGORE + county_data$PNADER

#categorical party var
county_geo_data<- left_join(US_county, county_data, by = c( "region" = "STATE", "subregion" = "COUNTY")) %>% 
  na.omit() %>% 
  mutate(party = derivedFactor(
    "D" = (PNADER_PGORE-PBUSH > .03),
    "R" = (PBUSH-PNADER_PGORE > .1),
    .method = "first",
    .default = "S"
    )) %>% 
  select(-PNADER, -PGORE)

#color scheme
myColors <- c("#1B338B","#8B1B33","#FFFFFF")
names(myColors) <- levels(county_geo_data$party)
colScale <- scale_fill_manual(name = "party",values = myColors, labels=c("Democrat", "Republican", "Split"))


#base map
g <- ggplot(data=NULL) +
geom_polygon(data=county_geo_data, aes(x=long, y=lat, group=group, fill=party)) +
geom_path(data=county_geo_data, aes(x=long, y=lat, group=group), col="grey", size=0.1) +
geom_path(data=US_state, aes(x=long, y=lat, group=group), col="black", size=0.2) +
coord_map() +
guides(fill=guide_legend(title=NULL))+
labs(title = "Prefered Party By County in the 2000 Election", x = "longitude", y = "latitude")+
  theme_map()+
  theme(legend.background = element_rect(fill="gray90", size=.5))

#add color
g+colScale

#gradient map
g2 <- ggplot(data=NULL) +
geom_polygon(data=county_geo_data, aes(x=long, y=lat, group=group, fill=PBUSH)) +
geom_path(data=county_geo_data, aes(x=long, y=lat, group=group), col="grey", size=0.1) +
geom_path(data=US_state, aes(x=long, y=lat, group=group), col="black", size=0.2) +
coord_map() +
guides(fill=guide_legend(title="Percent Republican"))+
labs(title = "Prefered Party By County in the 2000 Election", x = "longitude", y = "latitude")+
  theme_map()+
  theme(legend.background = element_rect(fill="gray90", size=.5))

colScale2 <- scale_fill_gradientn(colours = c("#1B338B","#FFFFFF","#8B1B33"))

#add color
g2+colScale2

```


### Write-Up

```{r, echo=FALSE, message=FALSE, warning=FALSE}
instate_variance <- county_geo_data %>% 
  mutate(county = paste(subregion, " ", region)) %>% 
  select(region, county, PBUSH) %>% 
  subset(!duplicated(county)) %>% 
  group_by(region) %>% 
  summarise(stateVar = sd(PBUSH)) 

county_geo_data<- left_join(county_geo_data,instate_variance)

gvar <- ggplot(data=NULL) +
geom_polygon(data=county_geo_data, aes(x=long, y=lat, group=group, fill=stateVar)) +
geom_path(data=US_state, aes(x=long, y=lat, group=group), col="black", size=0.2) +
coord_map() +
guides(fill=guide_legend(title="SD by county"))+
labs(title = "Diversity in Voting Patterns by State", x = "longitude", y = "latitude")+
  theme_map()+
  theme(legend.background = element_rect(fill="gray90", size=.5))

colScale3 <- scale_fill_gradientn(colours = c("white", "#2c7fb8", "black" ))

#add color
gvar+colScale3

```

A quick look at the standard deviation of county votes by state gives us some insight on how split the vote is in each state. New Mexico is the state with the highest standard deviation, its counties differ significantly in their voting patterns. It's also known to be a swing state. So is Colorado, 5th in voting diversity. Swing states are often racially diverse, and racial diversity may also play into voting diversity by county. Vermont, on the opposite extreme, is relatively homogenous in its vote, it is the fifth "most consistant" voting state. Most of New England follows this trend, perhap also hinting that racial diversity may be correlated to diversity in voting patterns.

## Question 2:

### Loading Shapefile Data

Here is some starter code:

```{r, echo=FALSE, message=FALSE, warning=FALSE}
#I'm not sure why these don't/rarely knit, they compile fine for me
#import, select, rename 
shapefile_name <- paste(getwd(), "/VT_census_tracts/tl_2015_50_tract.shp", sep="")
VT <- readOGR(shapefile_name, layer = "tl_2015_50_tract", verbose = FALSE)

vt_census <- read.csv("data/VT_census_tract.csv", header=TRUE) %>% 
  tbl_df()

vt_census <- select(vt_census,  GEOID = Geo_FIPS, total_pop = SE_T055_001, white = SE_T055_003, black = SE_T055_004, hispanic = SE_T055_010, native = SE_T055_005, asian = SE_T055_006, islander = SE_T055_007, other = SE_T055_008, mix = SE_T055_009)


#calc proportions
vt_census <- vt_census %>% mutate(
  prop_white = white/total_pop,
  prop_black = black/total_pop,
  prop_hispanic = hispanic/total_pop,
  prop_native = native/total_pop, 
  prop_asian = asian/total_pop, 
  prop_islander = islander/total_pop, 
  prop_other = other/total_pop,
  prop_mix = mix/total_pop)


base <- leaflet(VT) %>%
  addProviderTiles("CartoDB.Positron") %>%
  addPolylines(data = VT, color="#FFFFFF", weight=2)

#hispanic
pal <- colorQuantile("YlOrRd", NULL, n = 5)
base %>% addPolygons(
              fillColor = ~pal(1 - vt_census$prop_hispanic),#inverts color scheme
              fillOpacity = 0.5, 
              weight = 1)
#white
pal <- colorQuantile("YlGnBu", NULL, n = 5)
base %>% addPolygons(
              fillColor = ~pal(1 - vt_census$prop_white),#inverts color scheme
              fillOpacity = 0.5, 
              weight = 1)
#black
pal <- colorQuantile("RdPu", NULL, n = 5)
base %>% addPolygons(
              fillColor = ~pal(1 - vt_census$prop_black),#inverts color scheme
              fillOpacity = 0.5, 
              weight = 1)
#asian
pal <- colorQuantile("Oranges", NULL, n = 5)
base %>% addPolygons(
              fillColor = ~pal(1 - vt_census$prop_black),#inverts color scheme
              fillOpacity = 0.5, 
              weight = 1)

```


### Write-Up
Comment on general ethnic demographic trends that's more substantive than just
"Vermont is really white."



